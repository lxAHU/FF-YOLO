{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e35836d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from nets.CA import CoordAttention\n",
    "from nets.backbone import Backbone, C2f, Conv\n",
    "from nets.yolo_training import weights_init\n",
    "from utils.utils_bbox import make_anchors\n",
    "\n",
    "def fuse_conv_and_bn(conv, bn):\n",
    "    # 混合Conv2d + BatchNorm2d 减少计算量\n",
    "    # Fuse Conv2d() and BatchNorm2d() layers https://tehnokv.com/posts/fusing-batchnorm-and-conv/\n",
    "    fusedconv = nn.Conv2d(conv.in_channels,\n",
    "                          conv.out_channels,\n",
    "                          kernel_size=conv.kernel_size,\n",
    "                          stride=conv.stride,\n",
    "                          padding=conv.padding,\n",
    "                          dilation=conv.dilation,\n",
    "                          groups=conv.groups,\n",
    "                          bias=True).requires_grad_(False).to(conv.weight.device)\n",
    "\n",
    "    # 准备kernel\n",
    "    w_conv = conv.weight.clone().view(conv.out_channels, -1)\n",
    "    w_bn = torch.diag(bn.weight.div(torch.sqrt(bn.eps + bn.running_var)))\n",
    "    fusedconv.weight.copy_(torch.mm(w_bn, w_conv).view(fusedconv.weight.shape))\n",
    "\n",
    "    # 准备bias\n",
    "    b_conv = torch.zeros(conv.weight.size(0), device=conv.weight.device) if conv.bias is None else conv.bias\n",
    "    b_bn = bn.bias - bn.weight.mul(bn.running_mean).div(torch.sqrt(bn.running_var + bn.eps))\n",
    "    fusedconv.bias.copy_(torch.mm(w_bn, b_conv.reshape(-1, 1)).reshape(-1) + b_bn)\n",
    "\n",
    "    return fusedconv\n",
    "\n",
    "class DFL(nn.Module):\n",
    "    # DFL模块\n",
    "    # Distribution Focal Loss (DFL) proposed in Generalized Focal Loss https://ieeexplore.ieee.org/document/9792391\n",
    "    def __init__(self, c1=16):\n",
    "        super().__init__()\n",
    "        self.conv   = nn.Conv2d(c1, 1, 1, bias=False).requires_grad_(False)\n",
    "        x           = torch.arange(c1, dtype=torch.float)\n",
    "        self.conv.weight.data[:] = nn.Parameter(x.view(1, c1, 1, 1))\n",
    "        self.c1     = c1\n",
    "\n",
    "    def forward(self, x):\n",
    "        # bs, self.reg_max * 4, 8400\n",
    "        b, c, a = x.shape\n",
    "        # bs, 4, self.reg_max, 8400 => bs, self.reg_max, 4, 8400 => b, 4, 8400\n",
    "        # 以softmax的方式，对0~16的数字计算百分比，获得最终数字。\n",
    "        return self.conv(x.view(b, 4, self.c1, a).transpose(2, 1).softmax(1)).view(b, 4, a)\n",
    "        # return self.conv(x.view(b, self.c1, 4, a).softmax(1)).view(b, 4, a)\n",
    "\n",
    "        \n",
    "        \n",
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, c1, c2, k=3, s=2, p=1, d=1, act=True):\n",
    "        super().__init__()\n",
    "        self.depthconv = Conv(c1, c1, k, s, p, g=c1, d=d, act=act)  # Depthwise convolution\n",
    "        self.pointconv= Conv(c1, c2, 1, 1, act=act)  # Pointwise convolution\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthconv(x)\n",
    "        x = self.pointconv(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#---------------------------------------------------#\n",
    "#   yolo_body\n",
    "#---------------------------------------------------#\n",
    "class YoloBody(nn.Module):\n",
    "    def __init__(self, input_shape, num_classes, phi, pretrained=False):\n",
    "        super(YoloBody, self).__init__()\n",
    "        depth_dict          = {'n' : 0.33, 's' : 0.33, 'm' : 0.67, 'l' : 1.00, 'x' : 1.00,}\n",
    "        width_dict          = {'n' : 0.25, 's' : 0.50, 'm' : 0.75, 'l' : 1.00, 'x' : 1.25,}\n",
    "        deep_width_dict     = {'n' : 1.00, 's' : 1.00, 'm' : 0.75, 'l' : 0.50, 'x' : 0.50,}\n",
    "        dep_mul, wid_mul, deep_mul = depth_dict[phi], width_dict[phi], deep_width_dict[phi]\n",
    "\n",
    "        base_channels       = int(wid_mul * 64)  # 64\n",
    "        base_depth          = max(round(dep_mul * 3), 1)  # 3\n",
    "        #-----------------------------------------------#\n",
    "        #   输入图片是3, 640, 640\n",
    "        #-----------------------------------------------#\n",
    "\n",
    "        #---------------------------------------------------#   \n",
    "        #   生成主干模型\n",
    "        #   获得三个有效特征层，他们的shape分别是：\n",
    "        #   256, 80, 80\n",
    "        #   512, 40, 40\n",
    "        #   1024 * deep_mul, 20, 20\n",
    "        #---------------------------------------------------#\n",
    "        self.backbone   = Backbone(base_channels, base_depth, deep_mul, phi, pretrained=pretrained)\n",
    "\n",
    "        #------------------------加强特征提取网络------------------------# \n",
    "        self.upsample   = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "\n",
    "        # 1024 * deep_mul + 512, 40, 40 => 512, 40, 40\n",
    "        self.conv3_for_upsample1    = nn.Sequential(\n",
    "            C2f(int(base_channels * 16 * deep_mul) + base_channels * 8, base_channels * 8, base_depth, shortcut=False),\n",
    "             CoordAttention( base_channels * 8),\n",
    "                                                   )\n",
    "        # 768, 80, 80 => 256, 80, 80\n",
    "        self.conv3_for_upsample2    = nn.Sequential(\n",
    "            C2f(base_channels * 8 + base_channels * 4, base_channels * 4, base_depth, shortcut=False),\n",
    "            CoordAttention( base_channels * 4),\n",
    "                                                   )\n",
    "        # 256, 80, 80 => 256, 40, 40\n",
    "        self.down_sample1           = DepthwiseSeparableConv(base_channels * 4, base_channels * 4)\n",
    "        # 512 + 256, 40, 40 => 512, 40, 40\n",
    "        self.conv3_for_downsample1  = nn.Sequential(\n",
    "            C2f(base_channels * 8 + base_channels * 4, base_channels * 8, base_depth, shortcut=False),\n",
    "            CoordAttention( base_channels * 8),\n",
    "                                                   )\n",
    "\n",
    "        # 512, 40, 40 => 512, 20, 20\n",
    "        self.down_sample2           = DepthwiseSeparableConv(base_channels * 8, base_channels * 8)\n",
    "        # 1024 * deep_mul + 512, 20, 20 =>  1024 * deep_mul, 20, 20\n",
    "        self.conv3_for_downsample2  = nn.Sequential(\n",
    "            C2f(int(base_channels * 16 * deep_mul) + base_channels * 8, int(base_channels * 16 * deep_mul), base_depth, shortcut=False),\n",
    "            CoordAttention( int(base_channels * 16 * deep_mul)),\n",
    "                                                   )\n",
    "        #------------------------加强特征提取网络------------------------# \n",
    "        \n",
    "        ch              = [base_channels * 4, base_channels * 8, int(base_channels * 16 * deep_mul)]\n",
    "        self.shape      = None\n",
    "        self.nl         = len(ch)\n",
    "        # self.stride     = torch.zeros(self.nl)\n",
    "        self.stride     = torch.tensor([256 / x.shape[-2] for x in self.backbone.forward(torch.zeros(1, 3, 256, 256))])  # forward\n",
    "        self.reg_max    = 16  # DFL channels (ch[0] // 16 to scale 4/8/12/16/20 for n/s/m/l/x)\n",
    "        self.no         = num_classes + self.reg_max * 4  # number of outputs per anchor\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        c2, c3   = max((16, ch[0] // 4, self.reg_max * 4)), max(ch[0], num_classes)  # channels\n",
    "        self.cv2 = nn.ModuleList(nn.Sequential(Conv(x, c2, 3), Conv(c2, c2, 3), nn.Conv2d(c2, 4 * self.reg_max, 1)) for x in ch)\n",
    "        self.cv3 = nn.ModuleList(nn.Sequential(Conv(x, c3, 3), Conv(c3, c3, 3), nn.Conv2d(c3, num_classes, 1)) for x in ch)\n",
    "        if not pretrained:\n",
    "            weights_init(self)\n",
    "        self.dfl = DFL(self.reg_max) if self.reg_max > 1 else nn.Identity()\n",
    "\n",
    "\n",
    "    def fuse(self):\n",
    "        print('Fusing layers... ')\n",
    "        for m in self.modules():\n",
    "            if type(m) is Conv and hasattr(m, 'bn'):\n",
    "                m.conv = fuse_conv_and_bn(m.conv, m.bn)  # update conv\n",
    "                delattr(m, 'bn')  # remove batchnorm\n",
    "                m.forward = m.forward_fuse  # update forward\n",
    "        return self\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #  backbone\n",
    "        feat1, feat2, feat3 = self.backbone.forward(x)\n",
    "        \n",
    "        #------------------------加强特征提取网络------------------------# \n",
    "        # 1024 * deep_mul, 20, 20 => 1024 * deep_mul, 40, 40\n",
    "        P5_upsample = self.upsample(feat3)\n",
    "        # 1024 * deep_mul, 40, 40 cat 512, 40, 40 => 1024 * deep_mul + 512, 40, 40\n",
    "        P4          = torch.cat([P5_upsample, feat2], 1)\n",
    "        # 1024 * deep_mul + 512, 40, 40 => 512, 40, 40\n",
    "        P4          = self.conv3_for_upsample1(P4)\n",
    "\n",
    "        # 512, 40, 40 => 512, 80, 80\n",
    "        P4_upsample = self.upsample(P4)\n",
    "        # 512, 80, 80 cat 256, 80, 80 => 768, 80, 80\n",
    "        P3          = torch.cat([P4_upsample, feat1], 1)\n",
    "        # 768, 80, 80 => 256, 80, 80\n",
    "        P3          = self.conv3_for_upsample2(P3)\n",
    "\n",
    "        # 256, 80, 80 => 256, 40, 40\n",
    "        P3_downsample = self.down_sample1(P3)\n",
    "        # 512, 40, 40 cat 256, 40, 40 => 768, 40, 40\n",
    "        P4 = torch.cat([P3_downsample, P4], 1)\n",
    "        # 768, 40, 40 => 512, 40, 40\n",
    "        P4 = self.conv3_for_downsample1(P4)\n",
    "\n",
    "        # 512, 40, 40 => 512, 20, 20\n",
    "        P4_downsample = self.down_sample2(P4)\n",
    "        # 512, 20, 20 cat 1024 * deep_mul, 20, 20 => 1024 * deep_mul + 512, 20, 20\n",
    "        P5 = torch.cat([P4_downsample, feat3], 1)\n",
    "        # 1024 * deep_mul + 512, 20, 20 => 1024 * deep_mul, 20, 20\n",
    "        P5 = self.conv3_for_downsample2(P5)\n",
    "        #------------------------加强特征提取网络------------------------# \n",
    "        # P3 256, 80, 80\n",
    "        # P4 512, 40, 40\n",
    "        # P5 1024 * deep_mul, 20, 20\n",
    "        shape = P3.shape  # BCHW\n",
    "        \n",
    "        # P3 256, 80, 80 => num_classes + self.reg_max * 4, 80, 80\n",
    "        # P4 512, 40, 40 => num_classes + self.reg_max * 4, 40, 40\n",
    "        # P5 1024 * deep_mul, 20, 20 => num_classes + self.reg_max * 4, 20, 20\n",
    "        x = [P3, P4, P5]\n",
    "        for i in range(self.nl):\n",
    "            x[i] = torch.cat((self.cv2[i](x[i]), self.cv3[i](x[i])), 1)\n",
    "\n",
    "        if self.shape != shape:\n",
    "            self.anchors, self.strides = (x.transpose(0, 1) for x in make_anchors(x, self.stride, 0.5))\n",
    "            self.shape = shape\n",
    "        \n",
    "        # num_classes + self.reg_max * 4 , 8400 =>  cls num_classes, 8400; \n",
    "        #                                           box self.reg_max * 4, 8400\n",
    "        box, cls        = torch.cat([xi.view(shape[0], self.no, -1) for xi in x], 2).split((self.reg_max * 4, self.num_classes), 1)\n",
    "        # origin_cls      = [xi.split((self.reg_max * 4, self.num_classes), 1)[1] for xi in x]\n",
    "        dbox            = self.dfl(box)\n",
    "        return dbox, cls, x, self.anchors.to(dbox.device), self.strides.to(dbox.device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch[python3.9]",
   "language": "python",
   "name": "pytorchuse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
