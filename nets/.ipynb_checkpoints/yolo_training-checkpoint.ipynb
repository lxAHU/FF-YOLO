{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cbb51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from utils.utils_bbox import dist2bbox, make_anchors\n",
    "\n",
    "\n",
    "def select_candidates_in_gts(xy_centers, gt_bboxes, eps=1e-9, roll_out=False):\n",
    "    \"\"\"select the positive anchor center in gt\n",
    "\n",
    "    Args:\n",
    "        xy_centers (Tensor): shape(h*w, 4)\n",
    "        gt_bboxes (Tensor): shape(b, n_boxes, 4)\n",
    "    Return:\n",
    "        (Tensor): shape(b, n_boxes, h*w)\n",
    "    \"\"\"\n",
    "    n_anchors       = xy_centers.shape[0]\n",
    "    bs, n_boxes, _  = gt_bboxes.shape\n",
    "    # 计算每个真实框距离每个anchors锚点的左上右下的距离，然后求min\n",
    "    # 保证真实框在锚点附近，包围锚点\n",
    "    if roll_out:\n",
    "        bbox_deltas = torch.empty((bs, n_boxes, n_anchors), device=gt_bboxes.device)\n",
    "        for b in range(bs):\n",
    "            lt, rb          = gt_bboxes[b].view(-1, 1, 4).chunk(2, 2)  # left-top, right-bottom\n",
    "            bbox_deltas[b]  = torch.cat((xy_centers[None] - lt, rb - xy_centers[None]),\n",
    "                                       dim=2).view(n_boxes, n_anchors, -1).amin(2).gt_(eps)\n",
    "        return bbox_deltas\n",
    "    else:\n",
    "        # 真实框的坐上右下left-top, right-bottom \n",
    "        lt, rb      = gt_bboxes.view(-1, 1, 4).chunk(2, 2)  \n",
    "        # 真实框距离每个anchors锚点的左上右下的距离\n",
    "        bbox_deltas = torch.cat((xy_centers[None] - lt, rb - xy_centers[None]), dim=2).view(bs, n_boxes, n_anchors, -1)\n",
    "        # return (bbox_deltas.min(3)[0] > eps).to(gt_bboxes.dtype)\n",
    "        return bbox_deltas.amin(3).gt_(eps)\n",
    "\n",
    "\n",
    "def select_highest_overlaps(mask_pos, overlaps, n_max_boxes):\n",
    "    \"\"\"if an anchor box is assigned to multiple gts,\n",
    "        the one with the highest iou will be selected.\n",
    "\n",
    "    Args:\n",
    "        mask_pos (Tensor): shape(b, n_max_boxes, h*w)\n",
    "        overlaps (Tensor): shape(b, n_max_boxes, h*w)\n",
    "    Return:\n",
    "        target_gt_idx (Tensor): shape(b, h*w)\n",
    "        fg_mask (Tensor): shape(b, h*w)\n",
    "        mask_pos (Tensor): shape(b, n_max_boxes, h*w)\n",
    "    \"\"\"\n",
    "    # b, n_max_boxes, 8400 -> b, 8400\n",
    "    fg_mask = mask_pos.sum(-2)\n",
    "    # 如果有一个anchor被指派去预测多个真实框\n",
    "    if fg_mask.max() > 1:  \n",
    "        # b, n_max_boxes, 8400\n",
    "        mask_multi_gts      = (fg_mask.unsqueeze(1) > 1).repeat([1, n_max_boxes, 1])  \n",
    "        # 如果有一个anchor被指派去预测多个真实框，首先计算这个anchor最重合的真实框\n",
    "        # 然后做一个onehot\n",
    "        # b, 8400\n",
    "        max_overlaps_idx    = overlaps.argmax(1)  \n",
    "        # b, 8400, n_max_boxes\n",
    "        is_max_overlaps     = F.one_hot(max_overlaps_idx, n_max_boxes)  \n",
    "        # b, n_max_boxes, 8400\n",
    "        is_max_overlaps     = is_max_overlaps.permute(0, 2, 1).to(overlaps.dtype)  \n",
    "        # b, n_max_boxes, 8400\n",
    "        mask_pos            = torch.where(mask_multi_gts, is_max_overlaps, mask_pos) \n",
    "        fg_mask             = mask_pos.sum(-2)\n",
    "    # 找到每个anchor符合哪个gt\n",
    "    target_gt_idx = mask_pos.argmax(-2)  # (b, h*w)\n",
    "    return target_gt_idx, fg_mask, mask_pos\n",
    "\n",
    "\n",
    "class TaskAlignedAssigner(nn.Module):\n",
    "\n",
    "    def __init__(self, topk=13, num_classes=80, alpha=1.0, beta=6.0, eps=1e-9, roll_out_thr=0):\n",
    "        super().__init__()\n",
    "        self.topk           = topk\n",
    "        self.num_classes    = num_classes\n",
    "        self.bg_idx         = num_classes\n",
    "        self.alpha          = alpha\n",
    "        self.beta           = beta\n",
    "        self.eps            = eps\n",
    "        # roll_out_thr为64\n",
    "        self.roll_out_thr   = roll_out_thr\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, pd_scores, pd_bboxes, anc_points, gt_labels, gt_bboxes, mask_gt):\n",
    "        \"\"\"This code referenced to\n",
    "           https://github.com/Nioolek/PPYOLOE_pytorch/blob/master/ppyoloe/assigner/tal_assigner.py\n",
    "\n",
    "        Args:\n",
    "            pd_scores (Tensor)  : shape(bs, num_total_anchors, num_classes)\n",
    "            pd_bboxes (Tensor)  : shape(bs, num_total_anchors, 4)\n",
    "            anc_points (Tensor) : shape(num_total_anchors, 2)\n",
    "            gt_labels (Tensor)  : shape(bs, n_max_boxes, 1)\n",
    "            gt_bboxes (Tensor)  : shape(bs, n_max_boxes, 4)\n",
    "            mask_gt (Tensor)    : shape(bs, n_max_boxes, 1)\n",
    "        Returns:\n",
    "            target_labels (Tensor)  : shape(bs, num_total_anchors)\n",
    "            target_bboxes (Tensor)  : shape(bs, num_total_anchors, 4)\n",
    "            target_scores (Tensor)  : shape(bs, num_total_anchors, num_classes)\n",
    "            fg_mask (Tensor)        : shape(bs, num_total_anchors)\n",
    "        \"\"\"\n",
    "        # 获得batch_size \n",
    "        self.bs             = pd_scores.size(0)\n",
    "        # 获得真实框中的最大框数量\n",
    "        self.n_max_boxes    = gt_bboxes.size(1)\n",
    "        # 如果self.n_max_boxes大于self.roll_out_thr则roll_out\n",
    "        self.roll_out       = self.n_max_boxes > self.roll_out_thr if self.roll_out_thr else False\n",
    "    \n",
    "        if self.n_max_boxes == 0:\n",
    "            device = gt_bboxes.device\n",
    "            return (torch.full_like(pd_scores[..., 0], self.bg_idx).to(device), torch.zeros_like(pd_bboxes).to(device),\n",
    "                    torch.zeros_like(pd_scores).to(device), torch.zeros_like(pd_scores[..., 0]).to(device),\n",
    "                    torch.zeros_like(pd_scores[..., 0]).to(device))\n",
    "\n",
    "        # b, max_num_obj, 8400\n",
    "        # mask_pos      满足在真实框内、是真实框topk最重合的正样本、满足mask_gt的锚点\n",
    "        # align_metric  某个先验点属于某个真实框的类的概率乘上某个先验点与真实框的重合程度\n",
    "        # overlaps      所有真实框和锚点的重合程度\n",
    "        mask_pos, align_metric, overlaps = self.get_pos_mask(pd_scores, pd_bboxes, gt_labels, gt_bboxes, anc_points, mask_gt)\n",
    "\n",
    "        # target_gt_idx     b, 8400     每个anchor符合哪个gt\n",
    "        # fg_mask           b, 8400     每个anchor是否有符合的gt\n",
    "        # mask_pos          b, max_num_obj, 8400    one_hot后的target_gt_idx\n",
    "        target_gt_idx, fg_mask, mask_pos = select_highest_overlaps(mask_pos, overlaps, self.n_max_boxes)\n",
    "\n",
    "        # 指定目标到对应的anchor点上\n",
    "        # b, 8400\n",
    "        # b, 8400, 4\n",
    "        # b, 8400, 80\n",
    "        target_labels, target_bboxes, target_scores = self.get_targets(gt_labels, gt_bboxes, target_gt_idx, fg_mask)\n",
    "\n",
    "        # 乘上mask_pos，把不满足真实框满足的锚点的都置0\n",
    "        align_metric        *= mask_pos\n",
    "        # 每个真实框对应的最大得分\n",
    "        # b, max_num_obj\n",
    "        pos_align_metrics   = align_metric.amax(axis=-1, keepdim=True) \n",
    "        # 每个真实框对应的最大重合度\n",
    "        # b, max_num_obj\n",
    "        pos_overlaps        = (overlaps * mask_pos).amax(axis=-1, keepdim=True)\n",
    "        # 把每个真实框和先验点的得分乘上最大重合程度，再除上最大得分\n",
    "        norm_align_metric   = (align_metric * pos_overlaps / (pos_align_metrics + self.eps)).amax(-2).unsqueeze(-1)\n",
    "        # target_scores作为正则的标签\n",
    "        target_scores       = target_scores * norm_align_metric\n",
    "\n",
    "        return target_labels, target_bboxes, target_scores, fg_mask.bool(), target_gt_idx\n",
    "\n",
    "    def get_pos_mask(self, pd_scores, pd_bboxes, gt_labels, gt_bboxes, anc_points, mask_gt):\n",
    "        # pd_scores bs, num_total_anchors, num_classes\n",
    "        # pd_bboxes bs, num_total_anchors, 4\n",
    "        # gt_labels bs, n_max_boxes, 1\n",
    "        # gt_bboxes bs, n_max_boxes, 4\n",
    "        # \n",
    "        # align_metric是一个算出来的代价值，某个先验点属于某个真实框的类的概率乘上某个先验点与真实框的重合程度\n",
    "        # overlaps是某个先验点与真实框的重合程度\n",
    "        # align_metric, overlaps    bs, max_num_obj, 8400\n",
    "        align_metric, overlaps  = self.get_box_metrics(pd_scores, pd_bboxes, gt_labels, gt_bboxes)\n",
    "        \n",
    "        # 正样本锚点需要同时满足：\n",
    "        # 1、在真实框内\n",
    "        # 2、是真实框topk最重合的正样本\n",
    "        # 3、满足mask_gt\n",
    "        \n",
    "        # get in_gts mask           b, max_num_obj, 8400\n",
    "        # 判断先验点是否在真实框内\n",
    "        mask_in_gts             = select_candidates_in_gts(anc_points, gt_bboxes, roll_out=self.roll_out)\n",
    "        # get topk_metric mask      b, max_num_obj, 8400\n",
    "        # 判断锚点是否在真实框的topk中\n",
    "        mask_topk               = self.select_topk_candidates(align_metric * mask_in_gts, topk_mask=mask_gt.repeat([1, 1, self.topk]).bool())\n",
    "        # merge all mask to a final mask, b, max_num_obj, h*w\n",
    "        # 真实框存在，非padding\n",
    "        mask_pos                = mask_topk * mask_in_gts * mask_gt\n",
    "\n",
    "        return mask_pos, align_metric, overlaps\n",
    "\n",
    "    def get_box_metrics(self, pd_scores, pd_bboxes, gt_labels, gt_bboxes):\n",
    "        if self.roll_out:\n",
    "            align_metric    = torch.empty((self.bs, self.n_max_boxes, pd_scores.shape[1]), device=pd_scores.device)\n",
    "            overlaps        = torch.empty((self.bs, self.n_max_boxes, pd_scores.shape[1]), device=pd_scores.device)\n",
    "            ind_0           = torch.empty(self.n_max_boxes, dtype=torch.long)\n",
    "            for b in range(self.bs):\n",
    "                ind_0[:], ind_2 = b, gt_labels[b].squeeze(-1).long()\n",
    "                # 获得属于这个类别的得分\n",
    "                # bs, max_num_obj, 8400\n",
    "                bbox_scores     = pd_scores[ind_0, :, ind_2]  \n",
    "                # 计算真实框和预测框的ciou\n",
    "                # bs, max_num_obj, 8400\n",
    "                overlaps[b]     = bbox_iou(gt_bboxes[b].unsqueeze(1), pd_bboxes[b].unsqueeze(0), xywh=False, CIoU=True).squeeze(2).clamp(0)\n",
    "                align_metric[b] = bbox_scores.pow(self.alpha) * overlaps[b].pow(self.beta)\n",
    "        else:\n",
    "            # 2, b, max_num_obj\n",
    "            ind = torch.zeros([2, self.bs, self.n_max_boxes], dtype=torch.long)       \n",
    "            # b, max_num_obj  \n",
    "            # [0]代表第几个图片的\n",
    "            ind[0] = torch.arange(end=self.bs).view(-1, 1).repeat(1, self.n_max_boxes)  \n",
    "            # [1]真是标签是什么\n",
    "            ind[1] = gt_labels.long().squeeze(-1) \n",
    "            # 获得属于这个类别的得分\n",
    "            # 取出某个先验点属于某个类的概率\n",
    "            # b, max_num_obj, 8400\n",
    "            bbox_scores = pd_scores[ind[0], :, ind[1]]  \n",
    "\n",
    "            # 计算真实框和预测框的ciou\n",
    "            # bs, max_num_obj, 8400\n",
    "            overlaps        = bbox_iou(gt_bboxes.unsqueeze(2), pd_bboxes.unsqueeze(1), xywh=False, CIoU=True).squeeze(3).clamp(0)\n",
    "            align_metric    = bbox_scores.pow(self.alpha) * overlaps.pow(self.beta)\n",
    "        return align_metric, overlaps\n",
    "\n",
    "    def select_topk_candidates(self, metrics, largest=True, topk_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            metrics     : (b, max_num_obj, h*w).\n",
    "            topk_mask   : (b, max_num_obj, topk) or None\n",
    "        \"\"\"\n",
    "        # 8400\n",
    "        num_anchors             = metrics.shape[-1] \n",
    "        # b, max_num_obj, topk\n",
    "        topk_metrics, topk_idxs = torch.topk(metrics, self.topk, dim=-1, largest=largest)\n",
    "        if topk_mask is None:\n",
    "            topk_mask = (topk_metrics.max(-1, keepdim=True) > self.eps).tile([1, 1, self.topk])\n",
    "        # b, max_num_obj, topk\n",
    "        topk_idxs[~topk_mask] = 0\n",
    "        # b, max_num_obj, topk, 8400 -> b, max_num_obj, 8400\n",
    "        # 这一步得到的is_in_topk为b, max_num_obj, 8400\n",
    "        # 代表每个真实框对应的top k个先验点\n",
    "        if self.roll_out:\n",
    "            is_in_topk = torch.empty(metrics.shape, dtype=torch.long, device=metrics.device)\n",
    "            for b in range(len(topk_idxs)):\n",
    "                is_in_topk[b] = F.one_hot(topk_idxs[b], num_anchors).sum(-2)\n",
    "        else:\n",
    "            is_in_topk = F.one_hot(topk_idxs, num_anchors).sum(-2)\n",
    "        # 判断锚点是否在真实框的topk中\n",
    "        is_in_topk = torch.where(is_in_topk > 1, 0, is_in_topk)\n",
    "        return is_in_topk.to(metrics.dtype)\n",
    "\n",
    "    def get_targets(self, gt_labels, gt_bboxes, target_gt_idx, fg_mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            gt_labels       : (b, max_num_obj, 1)\n",
    "            gt_bboxes       : (b, max_num_obj, 4)\n",
    "            target_gt_idx   : (b, h*w)\n",
    "            fg_mask         : (b, h*w)\n",
    "        \"\"\"\n",
    "\n",
    "        # 用于读取真实框标签, (b, 1)\n",
    "        batch_ind       = torch.arange(end=self.bs, dtype=torch.int64, device=gt_labels.device)[..., None]\n",
    "        # b, h*w    获得gt_labels，gt_bboxes在flatten后的序号\n",
    "        target_gt_idx   = target_gt_idx + batch_ind * self.n_max_boxes\n",
    "        # b, h*w    用于flatten后读取标签\n",
    "        target_labels   = gt_labels.long().flatten()[target_gt_idx]\n",
    "        # b, h*w, 4 用于flatten后读取box\n",
    "        target_bboxes   = gt_bboxes.view(-1, 4)[target_gt_idx]\n",
    "        \n",
    "        # assigned target scores\n",
    "        target_labels.clamp(0)\n",
    "        # 进行one_hot映射到训练需要的形式。\n",
    "        target_scores   = F.one_hot(target_labels, self.num_classes)  # (b, h*w, 80)\n",
    "        fg_scores_mask  = fg_mask[:, :, None].repeat(1, 1, self.num_classes)  # (b, h*w, 80)\n",
    "        target_scores   = torch.where(fg_scores_mask > 0, target_scores, 0)\n",
    "\n",
    "        return target_labels, target_bboxes, target_scores\n",
    "\n",
    "def bbox_iou(box1, box2, xywh=True, GIoU=False, DIoU=False, CIoU=False, eps=1e-7):\n",
    "    # Returns Intersection over Union (IoU) of box1(1,4) to box2(n,4)\n",
    "\n",
    "    # Get the coordinates of bounding boxes\n",
    "    if xywh:  # transform from xywh to xyxy\n",
    "        (x1, y1, w1, h1), (x2, y2, w2, h2) = box1.chunk(4, -1), box2.chunk(4, -1)\n",
    "        w1_, h1_, w2_, h2_ = w1 / 2, h1 / 2, w2 / 2, h2 / 2\n",
    "        b1_x1, b1_x2, b1_y1, b1_y2 = x1 - w1_, x1 + w1_, y1 - h1_, y1 + h1_\n",
    "        b2_x1, b2_x2, b2_y1, b2_y2 = x2 - w2_, x2 + w2_, y2 - h2_, y2 + h2_\n",
    "    else:  # x1, y1, x2, y2 = box1\n",
    "        b1_x1, b1_y1, b1_x2, b1_y2 = box1.chunk(4, -1)\n",
    "        b2_x1, b2_y1, b2_x2, b2_y2 = box2.chunk(4, -1)\n",
    "        w1, h1 = b1_x2 - b1_x1, b1_y2 - b1_y1 + eps\n",
    "        w2, h2 = b2_x2 - b2_x1, b2_y2 - b2_y1 + eps\n",
    "\n",
    "    # Intersection area\n",
    "    inter = (b1_x2.minimum(b2_x2) - b1_x1.maximum(b2_x1)).clamp(0) * \\\n",
    "            (b1_y2.minimum(b2_y2) - b1_y1.maximum(b2_y1)).clamp(0)\n",
    "\n",
    "    # Union Area\n",
    "    union = w1 * h1 + w2 * h2 - inter + eps\n",
    "\n",
    "    # IoU\n",
    "    iou = inter / union\n",
    "    if CIoU or DIoU or GIoU:\n",
    "        cw = b1_x2.maximum(b2_x2) - b1_x1.minimum(b2_x1)  # convex (smallest enclosing box) width\n",
    "        ch = b1_y2.maximum(b2_y2) - b1_y1.minimum(b2_y1)  # convex height\n",
    "        if CIoU or DIoU:  # Distance or Complete IoU https://arxiv.org/abs/1911.08287v1\n",
    "            c2 = cw ** 2 + ch ** 2 + eps  # convex diagonal squared\n",
    "            rho2 = ((b2_x1 + b2_x2 - b1_x1 - b1_x2) ** 2 + (b2_y1 + b2_y2 - b1_y1 - b1_y2) ** 2) / 4  # center dist ** 2\n",
    "            if CIoU:  # https://github.com/Zzh-tju/DIoU-SSD-pytorch/blob/master/utils/box/box_utils.py#L47\n",
    "                v = (4 / math.pi ** 2) * (torch.atan(w2 / h2) - torch.atan(w1 / h1)).pow(2)\n",
    "                with torch.no_grad():\n",
    "                    alpha = v / (v - iou + (1 + eps))\n",
    "                return iou - (rho2 / c2 + v * alpha)  # CIoU\n",
    "            return iou - rho2 / c2  # DIoU\n",
    "        c_area = cw * ch + eps  # convex area\n",
    "        return iou - (c_area - union) / c_area  # GIoU https://arxiv.org/pdf/1902.09630.pdf\n",
    "    return iou  # IoU\n",
    "\n",
    "def bbox2dist(anchor_points, bbox, reg_max):\n",
    "    \"\"\"Transform bbox(xyxy) to dist(ltrb).\"\"\"\n",
    "    x1y1, x2y2 = torch.split(bbox, 2, -1)\n",
    "    return torch.cat((anchor_points - x1y1, x2y2 - anchor_points), -1).clamp(0, reg_max - 0.01)  # dist (lt, rb)\n",
    "\n",
    "class BboxLoss(nn.Module):\n",
    "    def __init__(self, reg_max=16, use_dfl=False):\n",
    "        super().__init__()\n",
    "        self.reg_max = reg_max\n",
    "        self.use_dfl = use_dfl\n",
    "\n",
    "    def forward(self, pred_dist, pred_bboxes, anchor_points, target_bboxes, target_scores, target_scores_sum, fg_mask):\n",
    "        # 计算IOU损失\n",
    "        # weight代表损失中标签应该有的置信度，0最小，1最大\n",
    "        weight      = torch.masked_select(target_scores.sum(-1), fg_mask).unsqueeze(-1)\n",
    "        # 计算预测框和真实框的重合程度\n",
    "        iou         = bbox_iou(pred_bboxes[fg_mask], target_bboxes[fg_mask], xywh=False, CIoU=True)\n",
    "        # 然后1-重合程度，乘上应该有的置信度，求和后求平均。\n",
    "        loss_iou    = ((1.0 - iou) * weight).sum() / target_scores_sum\n",
    "\n",
    "        # 计算DFL损失\n",
    "        if self.use_dfl:\n",
    "            target_ltrb = bbox2dist(anchor_points, target_bboxes, self.reg_max)\n",
    "            loss_dfl = self._df_loss(pred_dist[fg_mask].view(-1, self.reg_max + 1), target_ltrb[fg_mask]) * weight\n",
    "            loss_dfl = loss_dfl.sum() / target_scores_sum\n",
    "        else:\n",
    "            loss_dfl = torch.tensor(0.0).to(pred_dist.device)\n",
    "\n",
    "        return loss_iou, loss_dfl\n",
    "\n",
    "    @staticmethod\n",
    "    def _df_loss(pred_dist, target):\n",
    "        # Return sum of left and right DFL losses\n",
    "        # Distribution Focal Loss (DFL) proposed in Generalized Focal Loss https://ieeexplore.ieee.org/document/9792391\n",
    "        tl = target.long()  # target left\n",
    "        tr = tl + 1  # target right\n",
    "        wl = tr - target  # weight left\n",
    "        wr = 1 - wl  # weight right\n",
    "        # 一个点一般不会处于anchor点上，一般是xx.xx。如果要用DFL的话，不可能直接一个cross_entropy就能拟合\n",
    "        # 所以把它认为是相对于xx.xx左上角锚点与右下角锚点的距离 如果距离右下角锚点距离小，wl就小，左上角损失就小\n",
    "        #                                                   如果距离左上角锚点距离小，wr就小，右下角损失就小\n",
    "        return (F.cross_entropy(pred_dist, tl.view(-1), reduction=\"none\").view(tl.shape) * wl +\n",
    "                F.cross_entropy(pred_dist, tr.view(-1), reduction=\"none\").view(tl.shape) * wr).mean(-1, keepdim=True)\n",
    "\n",
    "def xywh2xyxy(x):\n",
    "    \"\"\"\n",
    "    Convert bounding box coordinates from (x, y, width, height) format to (x1, y1, x2, y2) format where (x1, y1) is the\n",
    "    top-left corner and (x2, y2) is the bottom-right corner.\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray) or (torch.Tensor): The input bounding box coordinates in (x, y, width, height) format.\n",
    "    Returns:\n",
    "        y (np.ndarray) or (torch.Tensor): The bounding box coordinates in (x1, y1, x2, y2) format.\n",
    "    \"\"\"\n",
    "    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n",
    "    y[..., 0] = x[..., 0] - x[..., 2] / 2  # top left x\n",
    "    y[..., 1] = x[..., 1] - x[..., 3] / 2  # top left y\n",
    "    y[..., 2] = x[..., 0] + x[..., 2] / 2  # bottom right x\n",
    "    y[..., 3] = x[..., 1] + x[..., 3] / 2  # bottom right y\n",
    "    return y\n",
    "\n",
    "# Criterion class for computing training losses\n",
    "class Loss:\n",
    "    def __init__(self, model): \n",
    "        self.bce    = nn.BCEWithLogitsLoss(reduction='none')\n",
    "        self.stride = model.stride  # model strides\n",
    "        self.nc     = model.num_classes  # number of classes\n",
    "        self.no     = model.no\n",
    "        self.reg_max = model.reg_max\n",
    "        \n",
    "        self.use_dfl = model.reg_max > 1\n",
    "        roll_out_thr = 64\n",
    "\n",
    "        self.assigner = TaskAlignedAssigner(topk=10,\n",
    "                                            num_classes=self.nc,\n",
    "                                            alpha=0.5,\n",
    "                                            beta=6.0,\n",
    "                                            roll_out_thr=roll_out_thr)\n",
    "        self.bbox_loss  = BboxLoss(model.reg_max - 1, use_dfl=self.use_dfl)\n",
    "        self.proj       = torch.arange(model.reg_max, dtype=torch.float)\n",
    "\n",
    "    def preprocess(self, targets, batch_size, scale_tensor):\n",
    "        if targets.shape[0] == 0:\n",
    "            out = torch.zeros(batch_size, 0, 5, device=targets.device)\n",
    "        else:\n",
    "            # 获得图像索引\n",
    "            i           = targets[:, 0]  \n",
    "            _, counts   = i.unique(return_counts=True)\n",
    "            out         = torch.zeros(batch_size, counts.max(), 5, device=targets.device)\n",
    "            # 对batch进行循环，然后赋值\n",
    "            for j in range(batch_size):\n",
    "                matches = i == j\n",
    "                n = matches.sum()\n",
    "                if n:\n",
    "                    out[j, :n] = targets[matches, 1:]\n",
    "            # 缩放到原图大小。\n",
    "            out[..., 1:5] = xywh2xyxy(out[..., 1:5].mul_(scale_tensor))\n",
    "        return out\n",
    "\n",
    "    def bbox_decode(self, anchor_points, pred_dist):\n",
    "        if self.use_dfl:\n",
    "            # batch, anchors, channels\n",
    "            b, a, c     = pred_dist.shape  \n",
    "            # DFL的解码\n",
    "            pred_dist   = pred_dist.view(b, a, 4, c // 4).softmax(3).matmul(self.proj.to(pred_dist.device).type(pred_dist.dtype))\n",
    "            # pred_dist = pred_dist.view(b, a, c // 4, 4).transpose(2,3).softmax(3).matmul(self.proj.type(pred_dist.dtype))\n",
    "            # pred_dist = (pred_dist.view(b, a, c // 4, 4).softmax(2) * self.proj.type(pred_dist.dtype).view(1, 1, -1, 1)).sum(2)\n",
    "        # 然后解码获得预测框\n",
    "        return dist2bbox(pred_dist, anchor_points, xywh=False)\n",
    "\n",
    "    def __call__(self, preds, batch):\n",
    "        # 获得使用的device\n",
    "        device  = preds[1].device\n",
    "        # box, cls, dfl三部分的损失\n",
    "        loss    = torch.zeros(3, device=device)  \n",
    "        # 获得特征，并进行划分\n",
    "        feats   = preds[2] if isinstance(preds, tuple) else preds\n",
    "        pred_distri, pred_scores = torch.cat([xi.view(feats[0].shape[0], self.no, -1) for xi in feats], 2).split((self.reg_max * 4, self.nc), 1)\n",
    "\n",
    "        # bs, num_classes + self.reg_max * 4 , 8400 =>  cls bs, num_classes, 8400; \n",
    "        #                                               box bs, self.reg_max * 4, 8400\n",
    "        pred_scores = pred_scores.permute(0, 2, 1).contiguous()\n",
    "        pred_distri = pred_distri.permute(0, 2, 1).contiguous()\n",
    "\n",
    "        # 获得batch size与dtype\n",
    "        dtype       = pred_scores.dtype\n",
    "        batch_size  = pred_scores.shape[0]\n",
    "        # 获得输入图片大小\n",
    "        imgsz       = torch.tensor(feats[0].shape[2:], device=device, dtype=dtype) * self.stride[0]  \n",
    "        # 获得anchors点和步长对应的tensor\n",
    "        anchor_points, stride_tensor = make_anchors(feats, self.stride, 0.5)\n",
    "\n",
    "        # 把一个batch中的东西弄一个矩阵\n",
    "        # 0为属于第几个图片\n",
    "        # 1为种类\n",
    "        # 2:为框的坐标\n",
    "        targets                 = torch.cat((batch[:, 0].view(-1, 1), batch[:, 1].view(-1, 1), batch[:, 2:]), 1)\n",
    "        # 先进行初步的处理，对输入进来的gt进行padding，到最大数量，并把框的坐标进行缩放\n",
    "        # bs, max_boxes_num, 5\n",
    "        targets                 = self.preprocess(targets.to(device), batch_size, scale_tensor=imgsz[[1, 0, 1, 0]])\n",
    "        # bs, max_boxes_num, 5 => bs, max_boxes_num, 1 ; bs, max_boxes_num, 4\n",
    "        gt_labels, gt_bboxes    = targets.split((1, 4), 2)  # cls, xyxy\n",
    "        # 求哪些框是有目标的，哪些是填充的\n",
    "        # bs, max_boxes_num\n",
    "        mask_gt                 = gt_bboxes.sum(2, keepdim=True).gt_(0)\n",
    "\n",
    "        # pboxes\n",
    "        # 对预测结果进行解码，获得预测框\n",
    "        # bs, 8400, 4\n",
    "        pred_bboxes             = self.bbox_decode(anchor_points, pred_distri)  # xyxy, (b, h*w, 4)\n",
    "\n",
    "        # 对预测框与真实框进行分配\n",
    "        # target_bboxes     bs, 8400, 4\n",
    "        # target_scores     bs, 8400, 80\n",
    "        # fg_mask           bs, 8400\n",
    "        _, target_bboxes, target_scores, fg_mask, _ = self.assigner(\n",
    "            pred_scores.detach().sigmoid(), (pred_bboxes.detach() * stride_tensor).type(gt_bboxes.dtype),\n",
    "            anchor_points * stride_tensor, gt_labels, gt_bboxes, mask_gt\n",
    "        )\n",
    "\n",
    "        target_bboxes       /= stride_tensor\n",
    "        target_scores_sum   = max(target_scores.sum(), 1)\n",
    "\n",
    "        # 计算分类的损失\n",
    "        # loss[1] = self.varifocal_loss(pred_scores, target_scores, target_labels) / target_scores_sum  # VFL way\n",
    "        loss[1] = self.bce(pred_scores, target_scores.to(dtype)).sum() / target_scores_sum  # BCE\n",
    "\n",
    "        # 计算bbox的损失\n",
    "        if fg_mask.sum():\n",
    "            loss[0], loss[2] = self.bbox_loss(pred_distri, pred_bboxes, anchor_points, target_bboxes, target_scores,\n",
    "                                              target_scores_sum, fg_mask)\n",
    "\n",
    "        loss[0] *= 7.5  # box gain\n",
    "        loss[1] *= 0.5  # cls gain\n",
    "        loss[2] *= 1.5  # dfl gain\n",
    "        return loss.sum() # loss(box, cls, dfl) # * batch_size\n",
    "\n",
    "def is_parallel(model):\n",
    "    # Returns True if model is of type DP or DDP\n",
    "    return type(model) in (nn.parallel.DataParallel, nn.parallel.DistributedDataParallel)\n",
    "\n",
    "def de_parallel(model):\n",
    "    # De-parallelize a model: returns single-GPU model if model is of type DP or DDP\n",
    "    return model.module if is_parallel(model) else model\n",
    "    \n",
    "def copy_attr(a, b, include=(), exclude=()):\n",
    "    # Copy attributes from b to a, options to only include [...] and to exclude [...]\n",
    "    for k, v in b.__dict__.items():\n",
    "        if (len(include) and k not in include) or k.startswith('_') or k in exclude:\n",
    "            continue\n",
    "        else:\n",
    "            setattr(a, k, v)\n",
    "\n",
    "class ModelEMA:\n",
    "    \"\"\" Updated Exponential Moving Average (EMA) from https://github.com/rwightman/pytorch-image-models\n",
    "    Keeps a moving average of everything in the model state_dict (parameters and buffers)\n",
    "    For EMA details see https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, decay=0.9999, tau=2000, updates=0):\n",
    "        # Create EMA\n",
    "        self.ema = deepcopy(de_parallel(model)).eval()  # FP32 EMA\n",
    "        # if next(model.parameters()).device.type != 'cpu':\n",
    "        #     self.ema.half()  # FP16 EMA\n",
    "        self.updates = updates  # number of EMA updates\n",
    "        self.decay = lambda x: decay * (1 - math.exp(-x / tau))  # decay exponential ramp (to help early epochs)\n",
    "        for p in self.ema.parameters():\n",
    "            p.requires_grad_(False)\n",
    "\n",
    "    def update(self, model):\n",
    "        # Update EMA parameters\n",
    "        with torch.no_grad():\n",
    "            self.updates += 1\n",
    "            d = self.decay(self.updates)\n",
    "\n",
    "            msd = de_parallel(model).state_dict()  # model state_dict\n",
    "            for k, v in self.ema.state_dict().items():\n",
    "                if v.dtype.is_floating_point:\n",
    "                    v *= d\n",
    "                    v += (1 - d) * msd[k].detach()\n",
    "\n",
    "    def update_attr(self, model, include=(), exclude=('process_group', 'reducer')):\n",
    "        # Update EMA attributes\n",
    "        copy_attr(self.ema, model, include, exclude)\n",
    "\n",
    "def weights_init(net, init_type='normal', init_gain = 0.02):\n",
    "    def init_func(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and classname.find('Conv') != -1:\n",
    "            if init_type == 'normal':\n",
    "                torch.nn.init.normal_(m.weight.data, 0.0, init_gain)\n",
    "            elif init_type == 'xavier':\n",
    "                torch.nn.init.xavier_normal_(m.weight.data, gain=init_gain)\n",
    "            elif init_type == 'kaiming':\n",
    "                torch.nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "            elif init_type == 'orthogonal':\n",
    "                torch.nn.init.orthogonal_(m.weight.data, gain=init_gain)\n",
    "            else:\n",
    "                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
    "        elif classname.find('BatchNorm2d') != -1:\n",
    "            torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "            torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "    print('initialize network with %s type' % init_type)\n",
    "    net.apply(init_func)\n",
    "\n",
    "def get_lr_scheduler(lr_decay_type, lr, min_lr, total_iters, warmup_iters_ratio = 0.05, warmup_lr_ratio = 0.1, no_aug_iter_ratio = 0.05, step_num = 10):\n",
    "    def yolox_warm_cos_lr(lr, min_lr, total_iters, warmup_total_iters, warmup_lr_start, no_aug_iter, iters):\n",
    "        if iters <= warmup_total_iters:\n",
    "            # lr = (lr - warmup_lr_start) * iters / float(warmup_total_iters) + warmup_lr_start\n",
    "            lr = (lr - warmup_lr_start) * pow(iters / float(warmup_total_iters), 2\n",
    "            ) + warmup_lr_start\n",
    "        elif iters >= total_iters - no_aug_iter:\n",
    "            lr = min_lr\n",
    "        else:\n",
    "            lr = min_lr + 0.5 * (lr - min_lr) * (\n",
    "                1.0\n",
    "                + math.cos(\n",
    "                    math.pi\n",
    "                    * (iters - warmup_total_iters)\n",
    "                    / (total_iters - warmup_total_iters - no_aug_iter)\n",
    "                )\n",
    "            )\n",
    "        return lr\n",
    "\n",
    "    def step_lr(lr, decay_rate, step_size, iters):\n",
    "        if step_size < 1:\n",
    "            raise ValueError(\"step_size must above 1.\")\n",
    "        n       = iters // step_size\n",
    "        out_lr  = lr * decay_rate ** n\n",
    "        return out_lr\n",
    "\n",
    "    if lr_decay_type == \"cos\":\n",
    "        warmup_total_iters  = min(max(warmup_iters_ratio * total_iters, 1), 3)\n",
    "        warmup_lr_start     = max(warmup_lr_ratio * lr, 1e-6)\n",
    "        no_aug_iter         = min(max(no_aug_iter_ratio * total_iters, 1), 15)\n",
    "        func = partial(yolox_warm_cos_lr ,lr, min_lr, total_iters, warmup_total_iters, warmup_lr_start, no_aug_iter)\n",
    "    else:\n",
    "        decay_rate  = (min_lr / lr) ** (1 / (step_num - 1))\n",
    "        step_size   = total_iters / step_num\n",
    "        func = partial(step_lr, lr, decay_rate, step_size)\n",
    "\n",
    "    return func\n",
    "\n",
    "def set_optimizer_lr(optimizer, lr_scheduler_func, epoch):\n",
    "    lr = lr_scheduler_func(epoch)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch[python3.9]",
   "language": "python",
   "name": "pytorchuse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
